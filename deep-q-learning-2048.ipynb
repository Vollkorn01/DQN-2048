{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Learning with the game 2048\n",
    "\n",
    "This repository trains a q deep learning network from the game 2048 and plots a performance graph. The gamelogic of the game 2048 is based on the implementation from Georg Wiese on his [GitHub Repo](https://github.com/georgwiese/2048-rl) and can for instance be played [here](http://2048game.com/de/). The deep q learning code is loosely based on the implementation form this [GitHub Repo](https://github.com/keon/deep-q-learning) tutorial and was enhanced and adapted to include the game 2048.\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "To start training, scroll down to the Cell called \"Train it\".\n",
    "\n",
    "### The game 2048\n",
    "\n",
    "2048 is a single-player sliding block puzzle game developed by Gabriele Cirulli in 2014. The game represents a 4 Ã— 4 grid where the value of each cell is a power of 2. An action can be any of the 4 movements: up, down, left right. When an action is performed, all cells move in the chosen direction. Any two adjacent cells with the same value (power of 2) along this direction merge to form one single cell with value equal to the sum of the two cells (i.e. the next power of 2). The objective of the game is to combine cells until reaching 2048. After each move, a new tile appears at a random empty cell. The game is finished/lost if all cells are full.\n",
    "To get a quick feeling of the game it is recommended to check out the free online version [here](http://2048game.com/).\n",
    "\n",
    "TODO: Include example of 2048 move and explain difficulties\n",
    "\n",
    "The gamelogic of the game 2048 can be found in the folder gamelogic in file game.py.\n",
    "\n",
    "### Strategies\n",
    "2048 is a game which starts easy but becomes very hard for human players. Obviously merging tiles whenever you can will get you to a certain level, but to reach a high score (or maximum value of e.g. 2048) there needs to be more sophisticated strategies. One of the most famous is to put the highest numbers in one corner, like it is explained  [here](https://www.cnet.com/news/2048-starts-easy-gets-hard-heres-how-to-make-it-easy-again/). This technique also used by the most successfull 2048 AIs, for example [this one](http://www.randalolson.com/2015/04/27/artificial-intelligence-has-crushed-all-human-records-in-2048-heres-how-the-ai-pulled-it-off/) using an expectimax algorithm. \n",
    "The challenge of this game for AI is the high amount of possible states (more than 16^12) combined with the randomness introduced when spawning the new tiles.\n",
    "\n",
    "### Q-Learning\n",
    "\n",
    "#### Reward\n",
    "Normally in games, the reward directly relates to the score of the game. In contrast in this game the official goal is to get a reach a 2048 tile (although the game does not stop there). \n",
    "The score is calculated in a way that it increases every time by the value of the newly merged tiles. For example is two 4s are merged the reward is 8.\n",
    "This means the score partly represents the highest value on the board but gives also an incentive to have multiple high value tiles compared to just looking at the maximum value present at the board.\n",
    "\n",
    "For our algorithm, we therefore implemented both versions of the reward, which results in a optimization of the score or a win-lose classification with a fixed target respectively.\n",
    "\n",
    "TODO As you can see in the section .... below x was better suited then y\n",
    "\n",
    "\n",
    "#### Loss\n",
    "In order to logically represent this intuition and train it, we need to express this as a formula that we can optimize on. The loss is just a value that indicates how far our prediction is from the actual target. For example, the prediction of the model could indicate that it sees more value in swiping left when in fact it can gain more reward by swiping upwards. We want to decrease this gap between the prediction and the target (loss). The loss is defined as:\n",
    "In our case this is calculated with this oneliner in the act funtion:\n",
    "\n",
    "$$ L = \\frac{1}{2} \\underbrace{\t[r + \\gamma*  max_{a'}Q(s',a')}_{\\mathrm{target}} -\\underbrace{Q(s,a)}_{\\mathrm{prediction}}]^2 $$\n",
    "\n",
    "whith the target looking like this in the code: \n",
    "target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "\n",
    "The repo consists of two parts: the learning part and the full programmed game of 2048.\n",
    "The gamelogic of the game 2048 can be found in the folder gamelogic in file game.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "First, we import the libraries and the gamelogic class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import time\n",
    "from shutil import copyfile\n",
    "import parameters\n",
    "import os\n",
    "\n",
    "from gamelogic.game Game\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Next, we define the number of episodes to play. One episode represents one played game and set the hyperparameters.\n",
    "Every 100 episodes, the values are being saved in the folder data and can be plotted with the file plot.py.\n",
    "We implemented an epsilon greedy algorithm with a decay. As you can see, the agent only explores in the beginning and starts decaying at a given rate epsilon_decay.\n",
    "\n",
    "\n",
    "The hyperparameters can be set in the file parameters.py.\n",
    "\n",
    "The most successful run was achieved using the following configuration:\n",
    "\n",
    "\n",
    "gamma = 0.00001\n",
    "In the case of taking one high maximum value as a reward, gamma can be set to be very low or even to 0 because it is very hard to reach a reward and there are no intermediate rewards so discounting should only be very small.\n",
    "In the case of score as reward and therefore the existence of intermediate rewards, gamma can be higher.\n",
    "\n",
    "epsilon_decay = 0.99992\n",
    "Epsilon decay determines how fast epsilon decays.\n",
    "We found 0.99992 is an apropriate amount, because it reaches the min_epsilon=0.01 after 60'000 episodes and our computing power restricts us to max 100'000 episodes.\n",
    "\n",
    "learning_rate = 0.001\n",
    "The learning_rate determines how fast gradient descent will find the solution but too large learning rate will lead to overshooting and not finding the optimal solution.\n",
    "We had the best results with a standard learning_rate of 0.001.\n",
    "\n",
    "batch_size = 32\n",
    "This determines the size of the batches used to replay and therefore to train the network.\n",
    "We found 32 to be used in most comparable problems and a batch size of 64 too slow down training too much without any improvements in the result.\n",
    "\n",
    "is_max_value_reward = True\n",
    "This is the boolean value which can be set to either using the score (false) or the maximum value as a reward(true).\n",
    "\n",
    "max_value_reward_threshold = 8\n",
    "This parameter determines the threshold which number the agent has to reach to get the reward. \n",
    "If this is set to 8, the agent has to reach a 2^9=512 tile to get the reward.\n",
    "\n",
    "max_value_reward_amount = 100\n",
    "This is only used if is_max_value_reward = True and determines the reward which the agent gets when reaching the threshold. Because discount rate is very small and there are no other rewards, this parameter does not have a big influence on the result.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "EPISODES = 1000\n",
    "\n",
    "path  = os.getcwd()\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.state_size = 16\n",
    "        self.action_size = 4 # (up, down, right, left)\n",
    "        self.memory = deque(maxlen=5000000)\n",
    "        self.gamma = parameters.gamma    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = parameters.epsilon_decay\n",
    "        self.learning_rate = parameters.learning_rate\n",
    "        self.model = self._build_model()\n",
    "        self.batch_size = parameters.batch_size\n",
    "        self.is_max_value_reward = parameters.is_max_value_reward\n",
    "        self.max_value_reward_threshold = parameters.max_value_reward_threshold\n",
    "        self.max_value_reward_amount = parameters.max_value_reward_amount\n",
    "        self.output_name = parameters.output_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network\n",
    "\n",
    "The deep network is a standard artificial neural network consisting of two fully connected hidden layers with 256 nodes each. As activation functions ReLu was used for all layers, which guarantees non vanishing gradients. The loss was computed using the mean squared error (mse). Bigger losses are therefore punished more. As optimizer we used Adam.\n",
    "\n",
    "Keras does all the work of subtracting the target from the neural network output and squaring it. It also applies the learning rate we defined while creating the neural network model. This all happens inside the fit() function we see later. This function decreases the gap between our prediction to target by the learning rate. The approximation of the Q-value converges to the true Q-value as we repeat the updating process. The loss will decrease and the score will go up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='relu'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember\n",
    "\n",
    "One of the challenges for DQN is that neural network used in the algorithm tends to forget the previous experiences as it overwrites them with new experiences. So we implemented a replay memory, stored as a list of previous experiences and observations to train the model with the previous experiences. We will call this array of experiences memory and use the remember() function to append state, action, reward, and next state to the memory.\n",
    "\n",
    "In our example, the memory list will have a form of:\n",
    "\n",
    "memory = [(state, action, reward, next_state, done)...]\n",
    "\n",
    "The remember function will simply store states, actions and resulting rewards to the memory like below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"algorithm tends to forget the previous experiences as it overwrites them with new experiences.\n",
    "        Therefore we re-train the model with previous experiences.\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Step\n",
    "\n",
    "The act method plays one move of a game. First we implement the epsilon-greedy algorithm and get the four Q-values (which are the output nodes of our neural network) associated with the four possible actions we can do in this move. We then compare these action values with the possible actions, since sometimes we are limited in the actions we can take. We choose the action with the highest Q value that we are allowed to take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.choice(game.available_actions())\n",
    "        #forward feeding\n",
    "        act_values = self.model.predict(state)\n",
    "        #temporarily sets q-values of not available actions to -100 so they are not chosen\n",
    "        if len(game.available_actions())< 4:\n",
    "          temp = game.available_actions()\n",
    "          for i in range(0, 4):\n",
    "            if i not in temp:\n",
    "              act_values[0][i] = -100\n",
    "        #returns action with highest q-value\n",
    "        return np.argmax(act_values[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay\n",
    "The replay function trains the neural network with experience from the memory. It first samples a minibatch from the memory. Each memory contains the current state, action, next state and its reward and a boolean done of each state of the minibatch, indicating whether the game is over.\n",
    "The Q learning algorithm is implemented as:\n",
    "```python\n",
    "target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "```\n",
    "where self.model.predict(next_state)[0] returns the Q-value of the next_state.\n",
    "\n",
    "```python\n",
    "self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "```\n",
    "trains one epoch by calculating the loss between the target q value and the predicted q value.\n",
    "Finally, we apply epsilon decay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"trains the neural net with experiences from memory (minibatches)\"\"\"\n",
    "        #samples mimibatch from memory\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        #for each memory\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            #if its final state set target to the reward\n",
    "            target = reward\n",
    "            if not done:\n",
    "                #set target according to formula\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "            #gets all 4 predictions from current state\n",
    "            target_f = self.model.predict(state)\n",
    "            #takes the one action which was selected in batch\n",
    "            target_f[0][action] = target\n",
    "            #trains the model\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and saving the weights\n",
    "The weights can be loaded and saved, so training can be interrupted and continued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "The main function loops through the episodes:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        game.new_game()\n",
    "        state = game.state()\n",
    "        state = np.reshape(state, [1, agent.state_size])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As long as the game is not over, the act function get's called to receive the calculated action, and the reward gets calculated. If is_max_value_reward is set to TRUE the reward gets calculated by getting the value of the maximum tile. We get this by looking up the highest value from the state variable, which is the playing field containing all tiles represented as a vector. <br>\n",
    "If is_max_value_reward is set to FALSE it takes the squared score The boolean done checks, whether the game is over and breaks the loop if so, to continue to the next episode:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "  while not game.game_over():\n",
    "            action = agent.act(state)\n",
    "            reward = (game.do_action(action))**2\n",
    "            if(agent.is_max_value_reward):\n",
    "                reward = 0\n",
    "                temp = game.state()\n",
    "                temp_reshaped = np.reshape(temp, [1, agent.state_size])\n",
    "                temp_max_value = np.amax(temp_reshaped[0])\n",
    "                if temp_max_value > agent.max_value_reward_threshold:\n",
    "                    reward = agent.max_value_reward_amount\n",
    "            next_state = game.state()\n",
    "            actions_available = game.available_actions()\n",
    "            if len(actions_available) == 0: \n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "            next_state = np.reshape(next_state, [1, agent.state_size])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                if (debug): print(\"no action available\")\n",
    "                states = game.state()\n",
    "                states = np.reshape(state, [1, agent.state_size])\n",
    "                max_value = np.amax(states[0])\n",
    "                output_list.append([e, np.asscalar(max_value), np.asscalar(game.score()), agent.epsilon])\n",
    "                if(debug):print(\"max_value: \" + str(max_value))\n",
    "                break\n",
    "        print(\"episodes: \" + str(e))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For plotting, we save the different parameters together with all the data into a json file:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "        if save_maxvalues:\n",
    "            if e == 100:\n",
    "                src = path + \"/learn.py\"\n",
    "                dst = path + \"/data/\"+agent.output_name+\"config.py\"\n",
    "                copyfile(src, dst)\n",
    "                output_list.insert(0, \"gamma: \"+str(parameters.gamma)+\" | epsilon decay: \"+str(parameters.epsilon_decay)+\" | learning rate: \"+str(parameters.learning_rate)+\"\\n batch size: \"+str(parameters.batch_size)+\" | reward = maxVal: \"+str(parameters.is_max_value_reward)+\" | reward amount: \"+str(parameters.max_value_reward_amount)+\" | reward threshold: \"+str(parameters.max_value_reward_threshold))\n",
    "            if e % 100 == 0:\n",
    "                with open(path + \"/data/\"+agent.output_name+\"output.txt\", \"w\") as outfile:\n",
    "                    json.dump(output_list, outfile)\n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "        if e % 10000 == 0:\n",
    "            timenow = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            savepath = path + \"/data/agent\"+agent.output_name+timenow+\"_Epi\"+str(e)\n",
    "            agent.save(savepath)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it\n",
    "Just execute the following cell. Can be executed at anytime, since values are being stored for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "from gamelogic.game import Game\n",
    "import time\n",
    "from shutil import copyfile\n",
    "import parameters\n",
    "import os\n",
    "\n",
    "EPISODES = 1000\n",
    "\n",
    "path  = os.getcwd()\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.state_size = 16\n",
    "        self.action_size = 4 # (up, down, right, left)\n",
    "        self.memory = deque(maxlen=5000000)\n",
    "        self.gamma = parameters.gamma    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = parameters.epsilon_decay\n",
    "        self.learning_rate = parameters.learning_rate\n",
    "        self.model = self._build_model()\n",
    "        self.batch_size = parameters.batch_size\n",
    "        self.is_max_value_reward = parameters.is_max_value_reward\n",
    "        self.max_value_reward_threshold = parameters.max_value_reward_threshold\n",
    "        self.max_value_reward_amount = parameters.max_value_reward_amount\n",
    "        self.output_name = parameters.output_name\n",
    "\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='relu'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"algorithm tends to forget the previous experiences as it overwrites them with new experiences.\n",
    "        Therefore we re-train the model with previous experiences.\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.choice(game.available_actions())\n",
    "        #forward feeding\n",
    "        act_values = self.model.predict(state)\n",
    "        #sets q-values of not available actions to -100 so they are not chosen\n",
    "        if len(game.available_actions())< 4:\n",
    "          temp = game.available_actions()\n",
    "          for i in range(0, 4):\n",
    "            if i not in temp:\n",
    "              act_values[0][i] = -100\n",
    "        #returns action with highest q-value\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"trains the neural net with experiences from memory (minibatches)\"\"\"\n",
    "        #samples mimibatch from memory\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        #for each memory\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            #if its final state set target to the reward\n",
    "            target = reward\n",
    "            if not done:\n",
    "                #set target according to formula\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "            #gets all 4 predictions from current state\n",
    "            target_f = self.model.predict(state)\n",
    "            #takes the one action which was selected in batch\n",
    "            target_f[0][action] = target\n",
    "            #trains the model\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    game = Game()\n",
    "    agent = DQNAgent()\n",
    "    # agent.load(\"./save/file\")\n",
    "    done = False\n",
    "    batch_size = agent.batch_size\n",
    "    debug = False\n",
    "    save_maxvalues = True\n",
    "    output_list = []\n",
    "\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        game.new_game()\n",
    "        state = game.state()\n",
    "        state = np.reshape(state, [1, agent.state_size])\n",
    "        while not game.game_over():\n",
    "            action = agent.act(state)\n",
    "            reward = (game.do_action(action))**2\n",
    "            if(agent.is_max_value_reward):\n",
    "                reward = 0\n",
    "                temp = game.state()\n",
    "                temp_reshaped = np.reshape(temp, [1, agent.state_size])\n",
    "                temp_max_value = np.amax(temp_reshaped[0])\n",
    "                if temp_max_value > agent.max_value_reward_threshold:\n",
    "                    reward = agent.max_value_reward_amount\n",
    "            next_state = game.state()\n",
    "            actions_available = game.available_actions()\n",
    "            if len(actions_available) == 0: \n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "            next_state = np.reshape(next_state, [1, agent.state_size])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                if (debug): print(\"no action available\")\n",
    "                states = game.state()\n",
    "                states = np.reshape(state, [1, agent.state_size])\n",
    "                max_value = np.amax(states[0])\n",
    "                output_list.append([e, np.asscalar(max_value), np.asscalar(game.score()), agent.epsilon])\n",
    "                if(debug):print(\"max_value: \" + str(max_value))\n",
    "                break\n",
    "        print(\"episodes: \" + str(e))\n",
    "\n",
    "        #save copy of configuration and the episode_maxvalue_data\n",
    "        if save_maxvalues:\n",
    "            if e == 100:\n",
    "                src = path + \"/learn.py\"\n",
    "                dst = path + \"/data/\"+agent.output_name+\"config.py\"\n",
    "                copyfile(src, dst)\n",
    "                output_list.insert(0, \"gamma: \"+str(parameters.gamma)+\" | epsilon decay: \"+str(parameters.epsilon_decay)+\" | learning rate: \"+str(parameters.learning_rate)+\"\\n batch size: \"+str(parameters.batch_size)+\" | reward = maxVal: \"+str(parameters.is_max_value_reward)+\" | reward amount: \"+str(parameters.max_value_reward_amount)+\" | reward threshold: \"+str(parameters.max_value_reward_threshold))\n",
    "            if e % 100 == 0:\n",
    "                with open(path + \"/data/\"+agent.output_name+\"output.txt\", \"w\") as outfile:\n",
    "                    json.dump(output_list, outfile)\n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "        if e % 10000 == 0:\n",
    "            timenow = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            savepath = path + \"/data/agent\"+agent.output_name+timenow+\"_Epi\"+str(e)\n",
    "            agent.save(savepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "As Plotting helps a lot to get the hyperparameters right and see the performance of the agent, a plotting function was developed to easily turn the training-data to a plot.\n",
    "To plot the values, just execute the following cell.\n",
    "By default, the average score, the average max value and the decaying epsilon are being plotted taking an average from a sample of the size set as the parameter stepsize, for example the first point is the average of the first 100 scores if the stepsize is set to 100.<br>\n",
    "If plot_max_instead_of_avg is set to TRUE, then instead of the average, the maximum values of every sample is plotted.<br>\n",
    "The inputname sets the name of the json file for the input data and therefore has to match the parameter set in parameters.py at the time of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
     "output_type": "stream",
      "this is titlegamma: 1e-05 | epsilon decay: 0.9995 | learning rate: 0.001\n",
      " batch size: 32 | reward = maxVal: True | reward amount: 100 | reward threshold: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAEhCAYAAAAH/xtqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28d195a5668>"
     },
     "metadata": {},
      ]
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#plotting info from https://matplotlib.org/gallery/ticks_and_spines/multiple_yaxis_with_spines.html\n",
    "\n",
    "\n",
    "#####SET PARAMETERS HERE######\n",
    "stepsize = 100\n",
    "plot_max_instead_of_avg = False\n",
    "inputname = \"test99\"\n",
    "debug = False\n",
    "#####SET PARAMETERS HERE######\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "def plot():\n",
    "    with open(path + '/data/'+inputname+'output.txt', \"r\") as infile:\n",
    "      inputlist = json.load(infile)\n",
    "      if (debug): print(\"path is: \" + str(path))\n",
    "      if (debug): print(\"list is: \" + str(inputlist))\n",
    "      #extract first item from list which is the configuration info\n",
    "\n",
    "      plottitle = inputlist[0]\n",
    "      inputlist.pop(0)\n",
    "      calculate_data(inputlist, plottitle)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data(inputlist, plottitle):\n",
    "  number_of_steps = int(len(inputlist) / stepsize)\n",
    "  if(debug):print(\"nr of steps is: \" + str(number_of_steps))\n",
    "\n",
    "  # EPISODES\n",
    "  episodes_list = []\n",
    "  for i in range(1, number_of_steps + 1):\n",
    "    episodes_list.append(i * stepsize);\n",
    "  if (debug):print(\"episode list: \" + str(episodes_list))\n",
    "\n",
    "  # Average Score\n",
    "  avg_score_list = []\n",
    "  for i in range(0, number_of_steps):\n",
    "    sum = 0\n",
    "    for j in range(0, stepsize):\n",
    "      sum = sum + inputlist[stepsize * i + j][2]\n",
    "    result = sum / (stepsize)\n",
    "    avg_score_list.append(result)\n",
    "  if (debug):print(\"avg_score_list: \" + str(avg_score_list))\n",
    "\n",
    "  # Average MaxValue\n",
    "  avg_max_value_list = []\n",
    "  for i in range(0, number_of_steps):\n",
    "    sum = 0\n",
    "    for j in range(0, stepsize):\n",
    "      sum = sum + inputlist[stepsize * i + j][1]\n",
    "    result = sum / float(stepsize)\n",
    "    avg_max_value_list.append(result)\n",
    "  if (debug):print(\"avg_max_value_list: \" + str(avg_max_value_list))\n",
    "\n",
    "  # Epsilon\n",
    "  epsilon_list = []\n",
    "  for i in range(0, number_of_steps):\n",
    "    result = inputlist[stepsize * i][3]\n",
    "    epsilon_list.append(result)\n",
    "  if (debug):print(\"epsilon_list: \" + str(epsilon_list))\n",
    "\n",
    "  # MaxScore\n",
    "  max_score_list = []\n",
    "  # make now list consisting only of scores\n",
    "  templist = [i[2] for i in inputlist]\n",
    "  for i in range(0, number_of_steps):\n",
    "    result = max(templist[i * stepsize:((i + 1) * stepsize)])\n",
    "    max_score_list.append(result)\n",
    "  if (debug):print(\"max_score: \" + str(max_score_list))\n",
    "\n",
    "  # MaxValue\n",
    "  max_value_list = []\n",
    "  # make now list consisting only of scores\n",
    "  templist_two = [i[1] for i in inputlist]\n",
    "  for i in range(0, number_of_steps):\n",
    "    result = max(templist_two[i * stepsize:((i + 1) * stepsize)])\n",
    "    max_value_list.append(result)\n",
    "  if (debug):print(\"max_value_list: \" + str(max_value_list))\n",
    "\n",
    "\n",
    "  if(plot_max_instead_of_avg):\n",
    "      plot_data(plottitle, max_x=len(inputlist)-(len(inputlist)%stepsize), para_episodes_list=episodes_list, para_value_list=max_value_list, para_score_list=max_score_list, para_epsilon_list=epsilon_list)\n",
    "  else:\n",
    "      plot_data(plottitle, max_x=len(inputlist)-(len(inputlist)%stepsize), para_episodes_list=episodes_list, para_value_list=avg_max_value_list, para_score_list=avg_score_list, para_epsilon_list=epsilon_list)\n",
    "\n",
    "\n",
    "def plot_data(plottitle, max_x, para_episodes_list, para_value_list, para_score_list, para_epsilon_list):\n",
    "    def make_patch_spines_invisible(ax):\n",
    "        ax.set_frame_on(True)\n",
    "        ax.patch.set_visible(False)\n",
    "        for sp in ax.spines.values():\n",
    "            sp.set_visible(False)\n",
    "\n",
    "\n",
    "    fig, host = plt.subplots()\n",
    "    fig.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    par2 = host.twinx()\n",
    "    par2.spines[\"right\"].set_position((\"axes\", 1.2))\n",
    "    make_patch_spines_invisible(par2)\n",
    "    par2.spines[\"right\"].set_visible(True)\n",
    "\n",
    "    #Score\n",
    "    p1, = host.plot(para_episodes_list, para_score_list, \"b-\", label=\"Score\")\n",
    "    #MaxValue\n",
    "    p2, = par1.plot(para_episodes_list, para_value_list, \"r-\", label=\"MaxValue\")\n",
    "    #Epsilon\n",
    "    p3, = par2.plot(para_episodes_list, para_epsilon_list, \"g-\", label=\"Epsilon\")\n",
    "\n",
    "    #Episodes\n",
    "    host.set_xlim(stepsize, max_x)\n",
    "    #Score\n",
    "    host.set_ylim(0, 3000)\n",
    "    #MaxValue\n",
    "    par1.set_ylim(0, 10)\n",
    "    #Epsilon\n",
    "    par2.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "    host.set_xlabel(\"Episodes\")\n",
    "    host.set_ylabel(\"Score\")\n",
    "    par1.set_ylabel(\"Max_Value\")\n",
    "    par2.set_ylabel(\"Epsilon\")\n",
    "    host.yaxis.label.set_color(p1.get_color())\n",
    "    par1.yaxis.label.set_color(p2.get_color())\n",
    "    par2.yaxis.label.set_color(p3.get_color())\n",
    "    tkw = dict(size=4, width=1.5)\n",
    "    host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "    par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "    par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n",
    "    host.tick_params(axis='x', **tkw)\n",
    "    lines = [p1, p2, p3]\n",
    "    host.legend(lines, [l.get_label() for l in lines])\n",
    "    plt.title(plottitle, fontsize=10)\n",
    "    plt.show()\n",
    "    fig.savefig(path + \"/graphs/\" + str(inputname)+\"graph.pdf\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Comparison of different configurations\n",
    "This sections shows the result of the different configuration of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "When we chose the game, we knew that it would be a hard one to play. Even for a human, there is no clear and obvious strategy in this game. <br>\n",
    "As expected the results were not extremely high.\n",
    "Training speed was slower then expected (3.5min/1000-game-episode), which was also caused by the rather slow hardware we were using. We also found that using a gpu did not increase the training speed, probably because of the low specs of the graphics card we used (gtx760 2GB).\n",
    "This made it difficult to play through the high amount of possible hyperparameter configurations.\n",
    "Still our agent is consistently beating a random player and is reaching a 1028 tile in some games, which is already rather hard to do for an unexperienced player.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
