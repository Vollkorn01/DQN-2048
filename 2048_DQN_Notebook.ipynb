{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Learning with the game 2048\n",
    "\n",
    "This repository trains a q deep learning network from the game 2048 and plots a performance graph. The gamelogic of the game 2048 is based on the implementation from Georg Wiese on his [GitHub Repo](https://github.com/georgwiese/2048-rl) and can for instance be played [here](http://2048game.com/de/). The deep q learning code is loosely based on the implementation form this [GitHub Repo](https://github.com/keon/deep-q-learning) tutorial and was enhanced and adapted to include the game 2048.\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Quickstart\n",
    "\n",
    "To start training, scroll down to the Cell called \"Train it\".\n",
    "\n",
    "### The game 2048\n",
    "\n",
    "2048 is a single-player sliding block puzzle game developed by Gabriele Cirulli in 2014. The game represents a 4 Ã— 4 grid where the value of each cell is a power of 2. An action can be any of the 4 movements: up, down, left right. When an action is performed, all cells move in the chosen direction. Any two adjacent cells with the same value (power of 2) along this direction merge to form one single cell with value equal to the sum of the two cells (i.e. the next power of 2). The objective of the game is to combine cells until reaching 2048. After each move, a new tile appears at a random empty cell. The game is finished/lost if all cells are full.\n",
    "To get a quick feeling of the game it is recommended to check out the free online version [here](http://2048game.com/).\n",
    "\n",
    "The game itself (gamelogic) of the game 2048 can be found in the folder gamelogic in file game.py.\n",
    "\n",
    "### Strategies\n",
    "2048 is a game which starts easy but becomes very hard for human players. Obviously merging tiles whenever you can will get you to a certain level, but to reach a high score (or maximum value of e.g. 2048) there needs to be more sophisticated strategies. One of the most famous is to put the highest numbers in one corner, like it is explained  [here](https://www.cnet.com/news/2048-starts-easy-gets-hard-heres-how-to-make-it-easy-again/). This technique also used by the most successfull 2048 AIs, for example [this one](http://www.randalolson.com/2015/04/27/artificial-intelligence-has-crushed-all-human-records-in-2048-heres-how-the-ai-pulled-it-off/) using an expectimax algorithm. \n",
    "The challenge of this game for AI is the high amount of possible states (more than 16^12) combined with the randomness introduced when spawning the new tiles.\n",
    "\n",
    "### Q-Learning\n",
    "\n",
    "#### Reward\n",
    "Normally in games, the reward directly relates to the score of the game. In contrast in this game the official goal is to get a reach a 2048 tile (although the game does not stop there). \n",
    "The score is calculated in a way that it increases every time by the value of the newly merged tiles. For example is two 4s are merged the reward is 8.\n",
    "This means the score partly represents the highest value on the board but gives also an incentive to have multiple high value tiles compared to just looking at the maximum value present at the board.\n",
    "\n",
    "For our algorithm, we therefore implemented both versions of the reward, which results in a optimization of the score or a win-lose classification with a fixed target respectively.\n",
    "\n",
    "As the results below show, we achieved similar results with both approaches.\n",
    "\n",
    "\n",
    "#### Loss\n",
    "In order to logically represent this intuition and train it, we need to express this as a formula that we can optimize on. The loss is just a value that indicates how far our prediction is from the actual target. For example, the prediction of the model could indicate that it sees more value in swiping left when in fact it can gain more reward by swiping upwards. We want to decrease this gap between the prediction and the target (loss). The loss is defined as:\n",
    "In our case this is calculated with this oneliner in the act funtion:\n",
    "\n",
    "$$ L = \\frac{1}{2} \\underbrace{\t[r + \\gamma*  max_{a'}Q(s',a')}_{\\mathrm{target}} -\\underbrace{Q(s,a)}_{\\mathrm{prediction}}]^2 $$\n",
    "\n",
    "whith the target looking like this in the code: <br>\n",
    "target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation \n",
    "The repo consists of two parts: the learning part and the full programmed game of 2048.\n",
    "The gamelogic of the game 2048 can be found in the folder gamelogic in file game.py.\n",
    "The code can be run on both python 2.7 and 3.5 versions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "Keras was used as neural network library. After testing with implementing tensorflow directly we found keras to be faster to code and easier to debug. \n",
    "Furthermore the simplicity of Keras allowed us to start from scratch and not getting biased from the implementation of [Georg Wiese](https://github.com/georgwiese/2048-rl).\n",
    "\n",
    "<br>First, we import the libraries and the gamelogic class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import time\n",
    "from shutil import copyfile\n",
    "import parameters\n",
    "import os\n",
    "\n",
    "from gamelogic.game Game\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Next, we define the number of episodes to play and set the hyperparameters.<br>\n",
    "The parameters can be set in a seperate file parameters.py.\n",
    "Every 100 episodes, key values are being saved in the folder data and can be plotted with the file plot.py.<br>\n",
    "We implemented an epsilon greedy algorithm with a decay. As you can see, the agent only explores in the beginning and starts decaying at a given rate epsilon_decay.<br>\n",
    "\n",
    "The hyperparameters used are explained below and an example is given for a successfull configuration using 100'000 episodes.<br>\n",
    "\n",
    "\n",
    "<b>gamma</b> = 0.001<br>\n",
    "In the case of taking one high maximum value as a reward, gamma can be set to be very low or even to 0 because it is very hard to reach a reward and there are no intermediate rewards so discounting should only be very small.\n",
    "In the case of score as reward and therefore the existence of intermediate rewards, gamma can be higher.\n",
    "\n",
    "<b>epsilon_decay</b> = 0.99992 <br>\n",
    "Epsilon decay determines how fast epsilon decays.\n",
    "We found 0.99992 is an apropriate amount, because it reaches the min_epsilon=0.01 after 60'000 episodes and our computing power restricts us to max 100'000 episodes.\n",
    "\n",
    "<b>learning_rate</b> = 0.01 <br>\n",
    "The learning_rate determines how fast gradient descent will find the solution but too large learning rate will lead to overshooting and not finding the optimal solution.\n",
    "We had the best results with a standard learning_rate of 0.01.\n",
    "\n",
    "<b>batch_size</b> = 32 <br>\n",
    "This determines the size of the batches used to replay and therefore to train the network.\n",
    "We found 32 to be used in most comparable problems and a batch size of 64 too slow down training too much without any improvements in the result.\n",
    "\n",
    "<b>is_max_value_reward </b>= True<br>\n",
    "This is the boolean value which can be set to either using the score (false) or the maximum value as a reward(true).\n",
    "\n",
    "<b>max_value_reward_threshold</b> = 8<br>\n",
    "This parameter determines the threshold which number the agent has to reach to get the reward. \n",
    "If this is set to 8, the agent has to reach a 2^9=512 tile to get the reward.\n",
    "\n",
    "<b>max_value_reward_amount</b> = 1000<br>\n",
    "This is only used if is_max_value_reward = True and determines the reward which the agent gets when reaching the threshold. Because discount rate is very small and there are no other rewards, this parameter does not have a big influence on the result.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the parameter.py file is feeded into the agent: <br>\n",
    "```python\n",
    "EPISODES = 1000\n",
    "\n",
    "path  = os.getcwd()\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.state_size = 16\n",
    "        self.action_size = 4 # (up, down, right, left)\n",
    "        self.memory = deque(maxlen=5000000)\n",
    "        self.gamma = parameters.gamma    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = parameters.epsilon_decay\n",
    "        self.learning_rate = parameters.learning_rate\n",
    "        self.model = self._build_model()\n",
    "        self.batch_size = parameters.batch_size\n",
    "        self.is_max_value_reward = parameters.is_max_value_reward\n",
    "        self.max_value_reward_threshold = parameters.max_value_reward_threshold\n",
    "        self.max_value_reward_amount = parameters.max_value_reward_amount\n",
    "        self.output_name = parameters.output_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network\n",
    "\n",
    "The deep network is a standard artificial neural network consisting of two fully connected hidden layers with 256 nodes each. As activation functions ReLu was used for all layers, which guarantees non vanishing gradients. The loss was computed using the mean squared error (mse). Bigger losses are therefore punished more. As optimizer we used Adam.\n",
    "\n",
    "Keras does all the work of subtracting the target from the neural network output and squaring it. It also applies the learning rate we defined while creating the neural network model. This all happens inside the fit() function we see later. This function decreases the gap between our prediction to target by the learning rate. The approximation of the Q-value converges to the true Q-value as we repeat the updating process. The loss will decrease and the score will go up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='relu'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember\n",
    "\n",
    "One of the challenges for DQN is that neural network used in the algorithm tends to forget the previous experiences as it overwrites them with new experiences. So we implemented a replay memory, stored as a list of previous experiences and observations to train the model with the previous experiences. We will call this array of experiences memory and use the remember() function to append state, action, reward, and next state to the memory.\n",
    "\n",
    "In our example, the memory list will have a form of:\n",
    "\n",
    "memory = [(state, action, reward, next_state, done)...]\n",
    "\n",
    "The remember function will simply store states, actions and resulting rewards to the memory like below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Step\n",
    "\n",
    "The act method plays one move of a game. First we implement the epsilon-greedy algorithm and get the four Q-values (which are the output nodes of our neural network) associated with the four possible actions we can do in this move. We then compare these action values with the possible actions, since sometimes we are limited in the actions we can take. We choose the action with the highest Q value that we are allowed to take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.choice(game.available_actions())\n",
    "        #forward feeding\n",
    "        act_values = self.model.predict(state)\n",
    "        #temporarily sets q-values of not available actions to -100 so they are not chosen\n",
    "        if len(game.available_actions())< 4:\n",
    "          temp = game.available_actions()\n",
    "          for i in range(0, 4):\n",
    "            if i not in temp:\n",
    "              act_values[0][i] = -100\n",
    "        #returns action with highest q-value\n",
    "        return np.argmax(act_values[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay\n",
    "The replay function trains the neural network with experience from the memory. It first samples a minibatch from the memory. Each memory contains the current state, action, next state and its reward and a boolean done of each state of the minibatch, indicating whether the game is over.\n",
    "The Q learning algorithm is implemented as:\n",
    "```python\n",
    "target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "```\n",
    "where self.model.predict(next_state)[0] returns the Q-value of the next_state.\n",
    "\n",
    "```python\n",
    "self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "```\n",
    "trains one epoch by calculating the loss between the target q value and the predicted q value.\n",
    "Finally, we apply epsilon decay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"trains the neural net with experiences from memory (minibatches)\"\"\"\n",
    "        #samples mimibatch from memory\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        #for each memory\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            #if its final state set target to the reward\n",
    "            target = reward\n",
    "            if not done:\n",
    "                #set target according to formula\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "            #gets all 4 predictions from current state\n",
    "            target_f = self.model.predict(state)\n",
    "            #takes the one action which was selected in batch\n",
    "            target_f[0][action] = target\n",
    "            #trains the model\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and saving the weights\n",
    "The weights can be loaded and saved, so training can be interrupted and continued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "The main function loops through the episodes:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        game.new_game()\n",
    "        state = game.state()\n",
    "        state = np.reshape(state, [1, agent.state_size])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As long as the game is not over, the act function get's called to receive the calculated action, and the reward gets calculated. If is_max_value_reward is set to TRUE the reward gets calculated by getting the value of the maximum tile. We get this by looking up the highest value from the state variable, which is the playing field containing all tiles represented as a vector. <br>\n",
    "If is_max_value_reward is set to FALSE it takes the squared score The boolean done checks, whether the game is over and breaks the loop if so, to continue to the next episode:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "  while not game.game_over():\n",
    "            action = agent.act(state)\n",
    "            reward = (game.do_action(action))**2\n",
    "            if(agent.is_max_value_reward):\n",
    "                reward = 0\n",
    "                temp = game.state()\n",
    "                temp_reshaped = np.reshape(temp, [1, agent.state_size])\n",
    "                temp_max_value = np.amax(temp_reshaped[0])\n",
    "                if temp_max_value > agent.max_value_reward_threshold:\n",
    "                    reward = agent.max_value_reward_amount\n",
    "            next_state = game.state()\n",
    "            actions_available = game.available_actions()\n",
    "            if len(actions_available) == 0: \n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "            next_state = np.reshape(next_state, [1, agent.state_size])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                if (debug): print(\"no action available\")\n",
    "                states = game.state()\n",
    "                states = np.reshape(state, [1, agent.state_size])\n",
    "                max_value = np.amax(states[0])\n",
    "                output_list.append([e, np.asscalar(max_value), np.asscalar(game.score()), agent.epsilon])\n",
    "                if(debug):print(\"max_value: \" + str(max_value))\n",
    "                break\n",
    "        print(\"episodes: \" + str(e))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For plotting, we save the different parameters together with all the data into a json file:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "        if save_maxvalues:\n",
    "            if e == 100:\n",
    "                src = path + \"/learn.py\"\n",
    "                dst = path + \"/data/\"+agent.output_name+\"config.py\"\n",
    "                copyfile(src, dst)\n",
    "                output_list.insert(0, \"gamma: \"+str(parameters.gamma)+\" | epsilon decay: \"+str(parameters.epsilon_decay)+\" | learning rate: \"+str(parameters.learning_rate)+\"\\n batch size: \"+str(parameters.batch_size)+\" | reward = maxVal: \"+str(parameters.is_max_value_reward)+\" | reward amount: \"+str(parameters.max_value_reward_amount)+\" | reward threshold: \"+str(parameters.max_value_reward_threshold))\n",
    "            if e % 100 == 0:\n",
    "                with open(path + \"/data/\"+agent.output_name+\"output.txt\", \"w\") as outfile:\n",
    "                    json.dump(output_list, outfile)\n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "        if e % 10000 == 0:\n",
    "            timenow = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            savepath = path + \"/data/agent\"+agent.output_name+timenow+\"_Epi\"+str(e)\n",
    "            agent.save(savepath)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it\n",
    "Just execute the following cell. Can be executed at anytime, since values are being stored for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes: 0\n",
      "episodes: 1\n",
      "episodes: 2\n",
      "episodes: 3\n",
      "episodes: 4\n",
      "episodes: 5\n",
      "episodes: 6\n",
      "episodes: 7\n",
      "episodes: 8\n",
      "episodes: 9\n",
      "episodes: 10\n",
      "episodes: 11\n",
      "episodes: 12\n",
      "episodes: 13\n",
      "episodes: 14\n",
      "episodes: 15\n",
      "episodes: 16\n",
      "episodes: 17\n",
      "episodes: 18\n",
      "episodes: 19\n",
      "episodes: 20\n",
      "episodes: 21\n",
      "episodes: 22\n",
      "episodes: 23\n",
      "episodes: 24\n",
      "episodes: 25\n",
      "episodes: 26\n",
      "episodes: 27\n",
      "episodes: 28\n",
      "episodes: 29\n",
      "episodes: 30\n",
      "episodes: 31\n",
      "episodes: 32\n",
      "episodes: 33\n",
      "episodes: 34\n",
      "episodes: 35\n",
      "episodes: 36\n",
      "episodes: 37\n",
      "episodes: 38\n",
      "episodes: 39\n",
      "episodes: 40\n",
      "episodes: 41\n",
      "episodes: 42\n",
      "episodes: 43\n",
      "episodes: 44\n",
      "episodes: 45\n",
      "episodes: 46\n",
      "episodes: 47\n",
      "episodes: 48\n",
      "episodes: 49\n",
      "episodes: 50\n",
      "episodes: 51\n",
      "episodes: 52\n",
      "episodes: 53\n",
      "episodes: 54\n",
      "episodes: 55\n",
      "episodes: 56\n",
      "episodes: 57\n",
      "episodes: 58\n",
      "episodes: 59\n",
      "episodes: 60\n",
      "episodes: 61\n",
      "episodes: 62\n",
      "episodes: 63\n",
      "episodes: 64\n",
      "episodes: 65\n",
      "episodes: 66\n",
      "episodes: 67\n",
      "episodes: 68\n",
      "episodes: 69\n",
      "episodes: 70\n",
      "episodes: 71\n",
      "episodes: 72\n",
      "episodes: 73\n",
      "episodes: 74\n",
      "episodes: 75\n",
      "episodes: 76\n",
      "episodes: 77\n",
      "episodes: 78\n",
      "episodes: 79\n",
      "episodes: 80\n",
      "episodes: 81\n",
      "episodes: 82\n",
      "episodes: 83\n",
      "episodes: 84\n",
      "episodes: 85\n",
      "episodes: 86\n",
      "episodes: 87\n",
      "episodes: 88\n",
      "episodes: 89\n",
      "episodes: 90\n",
      "episodes: 91\n",
      "episodes: 92\n",
      "episodes: 93\n",
      "episodes: 94\n",
      "episodes: 95\n",
      "episodes: 96\n",
      "episodes: 97\n",
      "episodes: 98\n",
      "episodes: 99\n",
      "episodes: 100\n",
      "episodes: 101\n",
      "episodes: 102\n",
      "episodes: 103\n",
      "episodes: 104\n",
      "episodes: 105\n",
      "episodes: 106\n",
      "episodes: 107\n",
      "episodes: 108\n",
      "episodes: 109\n",
      "episodes: 110\n",
      "episodes: 111\n",
      "episodes: 112\n",
      "episodes: 113\n",
      "episodes: 114\n",
      "episodes: 115\n",
      "episodes: 116\n",
      "episodes: 117\n",
      "episodes: 118\n",
      "episodes: 119\n",
      "episodes: 120\n",
      "episodes: 121\n",
      "episodes: 122\n",
      "episodes: 123\n",
      "episodes: 124\n",
      "episodes: 125\n",
      "episodes: 126\n",
      "episodes: 127\n",
      "episodes: 128\n",
      "episodes: 129\n",
      "episodes: 130\n",
      "episodes: 131\n",
      "episodes: 132\n",
      "episodes: 133\n",
      "episodes: 134\n",
      "episodes: 135\n",
      "episodes: 136\n",
      "episodes: 137\n",
      "episodes: 138\n",
      "episodes: 139\n",
      "episodes: 140\n",
      "episodes: 141\n",
      "episodes: 142\n",
      "episodes: 143\n",
      "episodes: 144\n",
      "episodes: 145\n",
      "episodes: 146\n",
      "episodes: 147\n",
      "episodes: 148\n",
      "episodes: 149\n",
      "episodes: 150\n",
      "episodes: 151\n",
      "episodes: 152\n",
      "episodes: 153\n",
      "episodes: 154\n",
      "episodes: 155\n",
      "episodes: 156\n",
      "episodes: 157\n",
      "episodes: 158\n",
      "episodes: 159\n",
      "episodes: 160\n",
      "episodes: 161\n",
      "episodes: 162\n",
      "episodes: 163\n",
      "episodes: 164\n",
      "episodes: 165\n",
      "episodes: 166\n",
      "episodes: 167\n",
      "episodes: 168\n",
      "episodes: 169\n",
      "episodes: 170\n",
      "episodes: 171\n",
      "episodes: 172\n",
      "episodes: 173\n",
      "episodes: 174\n",
      "episodes: 175\n",
      "episodes: 176\n",
      "episodes: 177\n",
      "episodes: 178\n",
      "episodes: 179\n",
      "episodes: 180\n",
      "episodes: 181\n",
      "episodes: 182\n",
      "episodes: 183\n",
      "episodes: 184\n",
      "episodes: 185\n",
      "episodes: 186\n",
      "episodes: 187\n",
      "episodes: 188\n",
      "episodes: 189\n",
      "episodes: 190\n",
      "episodes: 191\n",
      "episodes: 192\n",
      "episodes: 193\n",
      "episodes: 194\n",
      "episodes: 195\n",
      "episodes: 196\n",
      "episodes: 197\n",
      "episodes: 198\n",
      "episodes: 199\n",
      "episodes: 200\n",
      "episodes: 201\n",
      "episodes: 202\n",
      "episodes: 203\n",
      "episodes: 204\n",
      "episodes: 205\n",
      "episodes: 206\n",
      "episodes: 207\n",
      "episodes: 208\n",
      "episodes: 209\n",
      "episodes: 210\n",
      "episodes: 211\n",
      "episodes: 212\n",
      "episodes: 213\n",
      "episodes: 214\n",
      "episodes: 215\n",
      "episodes: 216\n",
      "episodes: 217\n",
      "episodes: 218\n",
      "episodes: 219\n",
      "episodes: 220\n",
      "episodes: 221\n",
      "episodes: 222\n",
      "episodes: 223\n",
      "episodes: 224\n",
      "episodes: 225\n",
      "episodes: 226\n",
      "episodes: 227\n",
      "episodes: 228\n",
      "episodes: 229\n",
      "episodes: 230\n",
      "episodes: 231\n",
      "episodes: 232\n",
      "episodes: 233\n",
      "episodes: 234\n",
      "episodes: 235\n",
      "episodes: 236\n",
      "episodes: 237\n",
      "episodes: 238\n",
      "episodes: 239\n",
      "episodes: 240\n",
      "episodes: 241\n",
      "episodes: 242\n",
      "episodes: 243\n",
      "episodes: 244\n",
      "episodes: 245\n",
      "episodes: 246\n",
      "episodes: 247\n",
      "episodes: 248\n",
      "episodes: 249\n",
      "episodes: 250\n",
      "episodes: 251\n",
      "episodes: 252\n",
      "episodes: 253\n",
      "episodes: 254\n",
      "episodes: 255\n",
      "episodes: 256\n",
      "episodes: 257\n",
      "episodes: 258\n",
      "episodes: 259\n",
      "episodes: 260\n",
      "episodes: 261\n",
      "episodes: 262\n",
      "episodes: 263\n",
      "episodes: 264\n",
      "episodes: 265\n",
      "episodes: 266\n",
      "episodes: 267\n",
      "episodes: 268\n",
      "episodes: 269\n",
      "episodes: 270\n",
      "episodes: 271\n",
      "episodes: 272\n",
      "episodes: 273\n",
      "episodes: 274\n",
      "episodes: 275\n",
      "episodes: 276\n",
      "episodes: 277\n",
      "episodes: 278\n",
      "episodes: 279\n",
      "episodes: 280\n",
      "episodes: 281\n",
      "episodes: 282\n",
      "episodes: 283\n",
      "episodes: 284\n",
      "episodes: 285\n",
      "episodes: 286\n",
      "episodes: 287\n",
      "episodes: 288\n",
      "episodes: 289\n",
      "episodes: 290\n",
      "episodes: 291\n",
      "episodes: 292\n",
      "episodes: 293\n",
      "episodes: 294\n",
      "episodes: 295\n",
      "episodes: 296\n",
      "episodes: 297\n",
      "episodes: 298\n",
      "episodes: 299\n",
      "episodes: 300\n",
      "episodes: 301\n",
      "episodes: 302\n",
      "episodes: 303\n",
      "episodes: 304\n",
      "episodes: 305\n",
      "episodes: 306\n",
      "episodes: 307\n",
      "episodes: 308\n",
      "episodes: 309\n",
      "episodes: 310\n",
      "episodes: 311\n",
      "episodes: 312\n",
      "episodes: 313\n",
      "episodes: 314\n",
      "episodes: 315\n",
      "episodes: 316\n",
      "episodes: 317\n",
      "episodes: 318\n",
      "episodes: 319\n",
      "episodes: 320\n",
      "episodes: 321\n",
      "episodes: 322\n",
      "episodes: 323\n",
      "episodes: 324\n",
      "episodes: 325\n",
      "episodes: 326\n",
      "episodes: 327\n",
      "episodes: 328\n",
      "episodes: 329\n",
      "episodes: 330\n",
      "episodes: 331\n",
      "episodes: 332\n",
      "episodes: 333\n",
      "episodes: 334\n",
      "episodes: 335\n",
      "episodes: 336\n",
      "episodes: 337\n",
      "episodes: 338\n",
      "episodes: 339\n",
      "episodes: 340\n",
      "episodes: 341\n",
      "episodes: 342\n",
      "episodes: 343\n",
      "episodes: 344\n",
      "episodes: 345\n",
      "episodes: 346\n",
      "episodes: 347\n",
      "episodes: 348\n",
      "episodes: 349\n",
      "episodes: 350\n",
      "episodes: 351\n",
      "episodes: 352\n",
      "episodes: 353\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-448f934a1c8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_max_value_reward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-448f934a1c8b>\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m#forward feeding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mact_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;31m#sets q-values of not available actions to -100 so they are not chosen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    911\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 913\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1713\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1267\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "from gamelogic.game import Game\n",
    "import time\n",
    "from shutil import copyfile\n",
    "import parameters\n",
    "import os\n",
    "\n",
    "EPISODES = 100000\n",
    "\n",
    "path  = os.getcwd()\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.state_size = 16\n",
    "        self.action_size = 4 # (up, down, right, left)\n",
    "        self.memory = deque(maxlen=5000000)\n",
    "        self.gamma = parameters.gamma    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = parameters.epsilon_decay\n",
    "        self.learning_rate = parameters.learning_rate\n",
    "        self.model = self._build_model()\n",
    "        self.batch_size = parameters.batch_size\n",
    "        self.is_max_value_reward = parameters.is_max_value_reward\n",
    "        self.max_value_reward_threshold = parameters.max_value_reward_threshold\n",
    "        self.max_value_reward_amount = parameters.max_value_reward_amount\n",
    "        self.output_name = parameters.output_name\n",
    "        filename = path + \"/data/\"\n",
    "        if not os.path.exists(filename):\n",
    "            os.makedirs(filename)\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='relu'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"algorithm tends to forget the previous experiences as it overwrites them with new experiences.\n",
    "        Therefore we re-train the model with previous experiences.\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.choice(game.available_actions())\n",
    "        #forward feeding\n",
    "        act_values = self.model.predict(state)\n",
    "        #sets q-values of not available actions to -100 so they are not chosen\n",
    "        if len(game.available_actions())< 4:\n",
    "          temp = game.available_actions()\n",
    "          for i in range(0, 4):\n",
    "            if i not in temp:\n",
    "              act_values[0][i] = -100\n",
    "        #returns action with highest q-value\n",
    "        return np.argmax(act_values[0])\n",
    "        #replace return with this for a random agent:\n",
    "        #return random.choice(game.available_actions())\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"trains the neural net with experiences from memory (minibatches)\"\"\"\n",
    "        #samples mimibatch from memory\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        #for each memory\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            #if its final state set target to the reward\n",
    "            target = reward\n",
    "            if not done:\n",
    "                #set target according to formula\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "            #gets all 4 predictions from current state\n",
    "            target_f = self.model.predict(state)\n",
    "            #takes the one action which was selected in batch\n",
    "            target_f[0][action] = target\n",
    "            #trains the model\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    game = Game()\n",
    "    agent = DQNAgent()\n",
    "    # agent.load(\"./save/file\")\n",
    "    done = False\n",
    "    batch_size = agent.batch_size\n",
    "    debug = False\n",
    "    save_maxvalues = True\n",
    "    output_list = []\n",
    "\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        game.new_game()\n",
    "        state = game.state()\n",
    "        state = np.reshape(state, [1, agent.state_size])\n",
    "        while not game.game_over():\n",
    "            action = agent.act(state)\n",
    "            reward = (game.do_action(action))**2\n",
    "            if(agent.is_max_value_reward):\n",
    "                reward = 0\n",
    "                temp = game.state()\n",
    "                temp_reshaped = np.reshape(temp, [1, agent.state_size])\n",
    "                temp_max_value = np.amax(temp_reshaped[0])\n",
    "                if temp_max_value > agent.max_value_reward_threshold:\n",
    "                    reward = agent.max_value_reward_amount\n",
    "            next_state = game.state()\n",
    "            actions_available = game.available_actions()\n",
    "            if len(actions_available) == 0:\n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "            next_state = np.reshape(next_state, [1, agent.state_size])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                if (debug): print(\"no action available\")\n",
    "                states = game.state()\n",
    "                states = np.reshape(state, [1, agent.state_size])\n",
    "                max_value = np.amax(states[0])\n",
    "                output_list.append([e, np.asscalar(max_value), np.asscalar(game.score()), agent.epsilon])\n",
    "                if(debug):print(\"max_value: \" + str(max_value))\n",
    "                break\n",
    "        print(\"episodes: \" + str(e))\n",
    "\n",
    "        #save copy of configuration and the episode_maxvalue_data\n",
    "        if save_maxvalues:\n",
    "            if e == 100:\n",
    "                output_list.insert(0, \"gamma: \"+str(parameters.gamma)+\" | epsilon decay: \"+str(parameters.epsilon_decay)+\" | learning rate: \"+str(parameters.learning_rate)+\"\\n batch size: \"+str(parameters.batch_size)+\" | reward = maxVal: \"+str(parameters.is_max_value_reward)+\" | reward amount: \"+str(parameters.max_value_reward_amount)+\" | reward threshold: \"+str(parameters.max_value_reward_threshold))\n",
    "            if e % 100 == 0:\n",
    "                with open(path + \"/data/\"+agent.output_name+\"output.txt\", \"w\") as outfile:\n",
    "                    json.dump(output_list, outfile)\n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "        if e % 10000 == 0:\n",
    "            timenow = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            savepath = path + \"/data/checkpoint\"\n",
    "            agent.save(savepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "As Plotting helps a lot to get the hyperparameters right and see the performance of the agent, a plotting function was developed to easily turn the training-data to a plot.\n",
    "To plot the values, just execute the following cell.\n",
    "By default, the average score, the average max value and the decaying epsilon are being plotted taking an average from a sample of the size set as the parameter stepsize, for example the first point is the average of the first 100 scores if the stepsize is set to 100.<br>\n",
    "If plot_max_instead_of_avg is set to TRUE, then instead of the average, the maximum values of every sample is plotted.<br>\n",
    "The inputname sets the name of the json file for the input data and therefore has to match the parameter set in parameters.py at the time of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23b51ba9550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#plotting info from https://matplotlib.org/gallery/ticks_and_spines/multiple_yaxis_with_spines.html\n",
    "\n",
    "\n",
    "#####SET PARAMETERS HERE######\n",
    "stepsize = 100\n",
    "plot_max_instead_of_avg = False\n",
    "inputname = \"test99\"\n",
    "debug = False\n",
    "#####SET PARAMETERS HERE######\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "def plot():\n",
    "    with open(path + '/data/'+inputname+'output.txt', \"r\") as infile:\n",
    "      inputlist = json.load(infile)\n",
    "      if (debug): print(\"path is: \" + str(path))\n",
    "      if (debug): print(\"list is: \" + str(inputlist))\n",
    "      #extract first item from list which is the configuration info\n",
    "\n",
    "      plottitle = inputlist[0]\n",
    "      inputlist.pop(0)\n",
    "      calculate_data(inputlist, plottitle)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data(inputlist, plottitle):\n",
    "  number_of_steps = int(len(inputlist) / stepsize)\n",
    "  if(debug):print(\"nr of steps is: \" + str(number_of_steps))\n",
    "\n",
    "  # EPISODES\n",
    "  episodes_list = []\n",
    "  for i in range(1, number_of_steps + 1):\n",
    "    episodes_list.append(i * stepsize);\n",
    "  if (debug):print(\"episode list: \" + str(episodes_list))\n",
    "\n",
    "  # Average Score\n",
    "  avg_score_list = []\n",
    "  for i in range(0, number_of_steps):\n",
    "    sum = 0\n",
    "    for j in range(0, stepsize):\n",
    "      sum = sum + inputlist[stepsize * i + j][2]\n",
    "    result = sum / (stepsize)\n",
    "    avg_score_list.append(result)\n",
    "  if (debug):print(\"avg_score_list: \" + str(avg_score_list))\n",
    "\n",
    "  # Average MaxValue\n",
    "  avg_max_value_list = []\n",
    "  for i in range(0, number_of_steps):\n",
    "    sum = 0\n",
    "    for j in range(0, stepsize):\n",
    "      sum = sum + inputlist[stepsize * i + j][1]\n",
    "    result = sum / float(stepsize)\n",
    "    avg_max_value_list.append(result)\n",
    "  if (debug):print(\"avg_max_value_list: \" + str(avg_max_value_list))\n",
    "\n",
    "  # Epsilon\n",
    "  epsilon_list = []\n",
    "  for i in range(0, number_of_steps):\n",
    "    result = inputlist[stepsize * i][3]\n",
    "    epsilon_list.append(result)\n",
    "  if (debug):print(\"epsilon_list: \" + str(epsilon_list))\n",
    "\n",
    "  # MaxScore\n",
    "  max_score_list = []\n",
    "  # make now list consisting only of scores\n",
    "  templist = [i[2] for i in inputlist]\n",
    "  for i in range(0, number_of_steps):\n",
    "    result = max(templist[i * stepsize:((i + 1) * stepsize)])\n",
    "    max_score_list.append(result)\n",
    "  if (debug):print(\"max_score: \" + str(max_score_list))\n",
    "\n",
    "  # MaxValue\n",
    "  max_value_list = []\n",
    "  # make now list consisting only of scores\n",
    "  templist_two = [i[1] for i in inputlist]\n",
    "  for i in range(0, number_of_steps):\n",
    "    result = max(templist_two[i * stepsize:((i + 1) * stepsize)])\n",
    "    max_value_list.append(result)\n",
    "  if (debug):print(\"max_value_list: \" + str(max_value_list))\n",
    "\n",
    "\n",
    "  if(plot_max_instead_of_avg):\n",
    "      plot_data(plottitle, max_x=len(inputlist)-(len(inputlist)%stepsize), para_episodes_list=episodes_list, para_value_list=max_value_list, para_score_list=max_score_list, para_epsilon_list=epsilon_list)\n",
    "  else:\n",
    "      plot_data(plottitle, max_x=len(inputlist)-(len(inputlist)%stepsize), para_episodes_list=episodes_list, para_value_list=avg_max_value_list, para_score_list=avg_score_list, para_epsilon_list=epsilon_list)\n",
    "\n",
    "\n",
    "def plot_data(plottitle, max_x, para_episodes_list, para_value_list, para_score_list, para_epsilon_list):\n",
    "    def make_patch_spines_invisible(ax):\n",
    "        ax.set_frame_on(True)\n",
    "        ax.patch.set_visible(False)\n",
    "        for sp in ax.spines.values():\n",
    "            sp.set_visible(False)\n",
    "\n",
    "\n",
    "    fig, host = plt.subplots()\n",
    "    fig.subplots_adjust(right=0.75)\n",
    "    par1 = host.twinx()\n",
    "    par2 = host.twinx()\n",
    "    par2.spines[\"right\"].set_position((\"axes\", 1.2))\n",
    "    make_patch_spines_invisible(par2)\n",
    "    par2.spines[\"right\"].set_visible(True)\n",
    "\n",
    "    #Score\n",
    "    p1, = host.plot(para_episodes_list, para_score_list, \"b-\", label=\"Score\")\n",
    "    #MaxValue\n",
    "    p2, = par1.plot(para_episodes_list, para_value_list, \"r-\", label=\"MaxValue\")\n",
    "    #Epsilon\n",
    "    p3, = par2.plot(para_episodes_list, para_epsilon_list, \"g-\", label=\"Epsilon\")\n",
    "\n",
    "    #Episodes\n",
    "    host.set_xlim(stepsize, max_x)\n",
    "    #Score\n",
    "    host.set_ylim(0, 9000)\n",
    "    #MaxValue\n",
    "    par1.set_ylim(6, 11)\n",
    "    #Epsilon\n",
    "    par2.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "    host.set_xlabel(\"Episodes\")\n",
    "    host.set_ylabel(\"Score\")\n",
    "    par1.set_ylabel(\"Max_Value\")\n",
    "    par2.set_ylabel(\"Epsilon\")\n",
    "    host.yaxis.label.set_color(p1.get_color())\n",
    "    par1.yaxis.label.set_color(p2.get_color())\n",
    "    par2.yaxis.label.set_color(p3.get_color())\n",
    "    tkw = dict(size=4, width=1.5)\n",
    "    host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "    par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "    par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n",
    "    host.tick_params(axis='x', **tkw)\n",
    "    lines = [p1, p2, p3]\n",
    "    host.legend(lines, [l.get_label() for l in lines])\n",
    "    plt.title(plottitle, fontsize=10)\n",
    "    additionalname = \"_avg_\"\n",
    "    if (plot_max_instead_of_avg): additionalname = \"_max_\"\n",
    "\n",
    "    figurepath = path + \"/graphs/\"\n",
    "    if not os.path.exists(figurepath):\n",
    "      os.makedirs(figurepath)\n",
    "    fig.savefig(figurepath + str(inputname)+additionalname+\"graph.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results\n",
    "Below is the comparison of 3 different configurations which we found to be the most successful configurations and a random moving agent.<br>\n",
    "(a) used a score based reward and (b) and (c) maximum value-based rewards. The difference between the latter two is that we set (c) up for a long training time and therefore set a higher threshold for the tile-value which it has to reach to get a reward (10 instead of 9). <br>\n",
    "The datapoints on the plots show the maximum or average results over 1000 episodes each.\n",
    "Overall we see a significant improvement in score and max_value compared to a random agent.<br> Our agent after reaching an average maxVal of 7.25 and a average score of 2200 after 60â€™000 episodes compared to a average maxVal of 6.58 and average score of 1050 of a random agent.<br>\n",
    "The graphs show that (c) performed worse than (b). We think this is because it is too unlikely to reach the defined reward threshold of 2^10 by random play and given the randomness in the game even harder to learn from those few occurences. <br>\n",
    "The highest tile we could reach was 2^10 which is 1024. Considering the exponential difficulty of the game, reaching 2048 would need a lot more training and optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_img/plot_comparison.png\" alt=\"Plots\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing the game\n",
    "During training, Keras saves a checkpoint of the model every 100 episodes. When running the following cell, One game is played using the latest checkpoint, displaying the game grid after every move. <br>\n",
    "There is also the possiblily to load the agent (a) from the plots above to skip learning and use a trained agent right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    2|     |    4|     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    2|    4|     |    2|\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    2|    4|    2|    2|\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    2|    4|    4|     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "|    2|    8|     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "|    4|    8|     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|     |     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|    4|    2|    2|     |\n",
      "-------------------------\n",
      "|    4|    8|     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    4|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    8|     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|    8|     |    2|     |\n",
      "-------------------------\n",
      "|    4|    8|     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|    4|    8|     |    2|\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    2|     |\n",
      "-------------------------\n",
      "|    2|     |    2|     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    2|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    4|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    2|    2|\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    8|    2|    2|     |\n",
      "-------------------------\n",
      "|    4|    8|    4|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    4|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    4|    2|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "|    4|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|    4|     |    2|     |\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|    4|    2|     |    2|\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|    4|    4|     |     |\n",
      "-------------------------\n",
      "|    8|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 400\n",
      "-------------------------\n",
      "|    8|    4|    4|    2|\n",
      "-------------------------\n",
      "|    4|    8|     |     |\n",
      "-------------------------\n",
      "|   16|    4|    4|     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|    8|    8|    2|     |\n",
      "-------------------------\n",
      "|    4|    8|     |     |\n",
      "-------------------------\n",
      "|   16|    8|     |     |\n",
      "-------------------------\n",
      "|     |     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "|    4|    8|     |     |\n",
      "-------------------------\n",
      "|   16|    8|     |     |\n",
      "-------------------------\n",
      "|    2|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "|    4|    8|     |     |\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|   16|    2|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|   16|     |    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|     |   16|    4|    2|\n",
      "-------------------------\n",
      "|     |     |    4|   16|\n",
      "-------------------------\n",
      "|    2|     |   16|    2|\n",
      "-------------------------\n",
      "|     |     |     |    4|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    2|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    2|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 1296\n",
      "-------------------------\n",
      "|   16|    4|    4|     |\n",
      "-------------------------\n",
      "|    4|   32|    2|     |\n",
      "-------------------------\n",
      "|    2|    2|     |     |\n",
      "-------------------------\n",
      "|    4|     |     |    4|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 400\n",
      "-------------------------\n",
      "|   16|    8|     |     |\n",
      "-------------------------\n",
      "|    4|   32|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|   32|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|   32|     |     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|   16|   32|     |     |\n",
      "-------------------------\n",
      "|    2|    4|     |     |\n",
      "-------------------------\n",
      "|     |    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   16|    8|    2|    2|\n",
      "-------------------------\n",
      "|   16|   32|     |     |\n",
      "-------------------------\n",
      "|    2|    4|     |     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   16|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|   32|     |     |\n",
      "-------------------------\n",
      "|    2|    4|     |     |\n",
      "-------------------------\n",
      "|    2|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   16|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|   32|     |     |\n",
      "-------------------------\n",
      "|    2|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 1024\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|   32|     |     |\n",
      "-------------------------\n",
      "|    4|    4|     |     |\n",
      "-------------------------\n",
      "|    2|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|   32|     |     |\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|   32|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|    4|     |    4|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|   32|     |    2|\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|   32|    2|     |\n",
      "-------------------------\n",
      "|    8|    2|    2|     |\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|   32|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |    2|\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|   32|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    8|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|   32|    2|    4|\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 400\n",
      "-------------------------\n",
      "|   32|    8|    4|    4|\n",
      "-------------------------\n",
      "|    2|   32|    4|     |\n",
      "-------------------------\n",
      "|   16|    4|     |    2|\n",
      "-------------------------\n",
      "|     |    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   32|    8|    8|     |\n",
      "-------------------------\n",
      "|    2|   32|    4|     |\n",
      "-------------------------\n",
      "|   16|    4|    2|    2|\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 400\n",
      "-------------------------\n",
      "|   32|   16|     |     |\n",
      "-------------------------\n",
      "|    2|   32|    4|     |\n",
      "-------------------------\n",
      "|   16|    4|    4|    4|\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   32|   16|     |     |\n",
      "-------------------------\n",
      "|    2|   32|    4|     |\n",
      "-------------------------\n",
      "|   16|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   32|   16|     |     |\n",
      "-------------------------\n",
      "|    2|   32|    4|     |\n",
      "-------------------------\n",
      "|   16|    8|    4|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   32|   16|    8|    2|\n",
      "-------------------------\n",
      "|    2|   32|     |     |\n",
      "-------------------------\n",
      "|   16|    8|     |     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   32|   16|    8|    2|\n",
      "-------------------------\n",
      "|     |     |    2|   32|\n",
      "-------------------------\n",
      "|    2|     |   16|    8|\n",
      "-------------------------\n",
      "|     |     |    4|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   32|   16|    8|    2|\n",
      "-------------------------\n",
      "|    2|   32|     |     |\n",
      "-------------------------\n",
      "|    2|   16|    8|    2|\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 576\n",
      "-------------------------\n",
      "|   32|   16|   16|    4|\n",
      "-------------------------\n",
      "|    4|   32|     |     |\n",
      "-------------------------\n",
      "|    4|   16|     |    2|\n",
      "-------------------------\n",
      "|     |    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 1024\n",
      "-------------------------\n",
      "|   32|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   32|     |     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    2|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 4624\n",
      "-------------------------\n",
      "|   64|    4|     |     |\n",
      "-------------------------\n",
      "|    4|   32|     |    2|\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   64|    4|     |     |\n",
      "-------------------------\n",
      "|    4|   32|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   64|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|   32|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|   64|    4|    4|     |\n",
      "-------------------------\n",
      "|    8|   32|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|     |    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   64|    8|     |     |\n",
      "-------------------------\n",
      "|    8|   32|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    2|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   64|    8|     |     |\n",
      "-------------------------\n",
      "|    8|   32|    2|    2|\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   64|    8|     |     |\n",
      "-------------------------\n",
      "|    8|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|    8|   32|    2|     |\n",
      "-------------------------\n",
      "|    8|   16|    2|     |\n",
      "-------------------------\n",
      "|     |    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|    8|   32|    2|     |\n",
      "-------------------------\n",
      "|    8|   16|    2|     |\n",
      "-------------------------\n",
      "|    2|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|    8|   32|    2|     |\n",
      "-------------------------\n",
      "|    8|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 400\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|     |    2|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    4|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    4|    2|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    4|    4|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   64|    8|    8|     |\n",
      "-------------------------\n",
      "|   16|   32|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 400\n",
      "-------------------------\n",
      "|   64|   16|     |    4|\n",
      "-------------------------\n",
      "|   16|   32|    2|     |\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   64|   16|    4|     |\n",
      "-------------------------\n",
      "|   16|   32|    2|    4|\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   64|   16|    4|    4|\n",
      "-------------------------\n",
      "|   16|   32|    2|    4|\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   64|   16|    8|     |\n",
      "-------------------------\n",
      "|   16|   32|    2|    4|\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|    8|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   64|   16|    8|     |\n",
      "-------------------------\n",
      "|   16|   32|    2|    4|\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    4|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    8|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 400\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|   32|    4|     |\n",
      "-------------------------\n",
      "|    4|   16|    2|    2|\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|   32|    4|    4|\n",
      "-------------------------\n",
      "|    4|   16|    4|     |\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|   32|    8|     |\n",
      "-------------------------\n",
      "|    4|   16|    4|    2|\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|   64|   16|   16|    4|\n",
      "-------------------------\n",
      "|   16|   32|    4|    2|\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 1024\n",
      "-------------------------\n",
      "|   64|   32|    4|    2|\n",
      "-------------------------\n",
      "|   16|   32|    4|    2|\n",
      "-------------------------\n",
      "|    4|   16|     |     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 5776\n",
      "-------------------------\n",
      "|   64|   64|    8|    4|\n",
      "-------------------------\n",
      "|   16|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|    4|     |     |\n",
      "-------------------------\n",
      "|   16|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 28224\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   32|    2|     |     |\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "|   16|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   32|    2|     |     |\n",
      "-------------------------\n",
      "|    8|     |    2|     |\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   32|    2|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|   16|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   32|    2|     |    2|\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   32|    4|    2|     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   32|    4|    4|     |\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   32|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 576\n",
      "-------------------------\n",
      "|  128|   16|    4|     |\n",
      "-------------------------\n",
      "|   32|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   16|    4|     |\n",
      "-------------------------\n",
      "|   32|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "|   16|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   16|    4|    4|\n",
      "-------------------------\n",
      "|   32|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|   16|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   16|    8|     |\n",
      "-------------------------\n",
      "|   32|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|   16|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   16|    8|     |\n",
      "-------------------------\n",
      "|   32|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|   16|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   16|    8|     |\n",
      "-------------------------\n",
      "|   32|    8|    2|    4|\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|    8|     |     |\n",
      "-------------------------\n",
      "|   16|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|  128|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    2|     |\n",
      "-------------------------\n",
      "|   16|     |     |    2|\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    2|    2|\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|    2|     |    2|\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|    4|\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    8|     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|  128|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    2|     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "|   16|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 4624\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    4|    4|     |\n",
      "-------------------------\n",
      "|   32|    2|     |     |\n",
      "-------------------------\n",
      "|     |    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|   32|    2|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|   32|    4|     |     |\n",
      "-------------------------\n",
      "|    4|     |    4|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|   32|    4|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 4096\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|     |    2|\n",
      "-------------------------\n",
      "|     |    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    2|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|    8|     |    2|\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|    8|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|    8|    2|    2|\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|    4|     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|     |   64|    8|    4|\n",
      "-------------------------\n",
      "|    2|    8|    4|    2|\n",
      "-------------------------\n",
      "|     |    4|    2|    4|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|    8|    4|    2|\n",
      "-------------------------\n",
      "|    2|    8|    4|    2|\n",
      "-------------------------\n",
      "|    4|    2|    4|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 784\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|    2|    4|    2|\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|    8|    4|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 576\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    4|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 784\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    4|     |\n",
      "-------------------------\n",
      "|   16|    8|     |     |\n",
      "-------------------------\n",
      "|     |     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    4|     |\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|     |   64|   16|    4|\n",
      "-------------------------\n",
      "|     |   16|    8|    2|\n",
      "-------------------------\n",
      "|    2|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    4|    2|\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    4|    2|\n",
      "-------------------------\n",
      "|     |   16|    8|    2|\n",
      "-------------------------\n",
      "|     |    2|     |    4|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    4|    2|\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|    2|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    4|    2|\n",
      "-------------------------\n",
      "|   16|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    4|    2|\n",
      "-------------------------\n",
      "|   16|    8|    4|    2|\n",
      "-------------------------\n",
      "|    2|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|    2|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|    4|    4|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|    8|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   16|   16|    4|    2|\n",
      "-------------------------\n",
      "|    2|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 1296\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|   32|    4|    2|     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|     |     |    8|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|    8|    4|     |    4|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|    8|    8|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|   16|    2|     |    2|\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|    2|   16|    4|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    8|    4|\n",
      "-------------------------\n",
      "|     |   16|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    2|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    4|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    4|    4|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|    4|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 576\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|   16|    8|\n",
      "-------------------------\n",
      "|    4|   32|    4|    2|\n",
      "-------------------------\n",
      "|   16|    8|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 1024\n",
      "-------------------------\n",
      "|  128|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    2|\n",
      "-------------------------\n",
      "|    4|   32|    4|    2|\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 4624\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|   16|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|   16|    2|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "|    2|   16|    4|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|    8|    8|    4|\n",
      "-------------------------\n",
      "|    2|   16|     |    4|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|   16|    4|     |\n",
      "-------------------------\n",
      "|    2|   16|    4|    4|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|   16|    4|    2|\n",
      "-------------------------\n",
      "|    2|   16|    8|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 1024\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    4|    2|\n",
      "-------------------------\n",
      "|    2|    2|    8|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   32|    8|    4|\n",
      "-------------------------\n",
      "|    4|   32|    4|    2|\n",
      "-------------------------\n",
      "|    4|    8|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 5184\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|   64|   64|    8|    4|\n",
      "-------------------------\n",
      "|    8|    8|    4|    2|\n",
      "-------------------------\n",
      "|    2|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 21904\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|    4|    2|    2|\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|    4|    4|     |\n",
      "-------------------------\n",
      "|    4|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|    4|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  128|   64|   16|    8|\n",
      "-------------------------\n",
      "|  128|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|    8|    2|    4|\n",
      "-------------------------\n",
      "|    8|     |     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 73984\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   16|   16|    4|    4|\n",
      "-------------------------\n",
      "|    8|     |    2|    2|\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 1936\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "|     |    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|     |    2|\n",
      "-------------------------\n",
      "|    2|     |     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    2|     |    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "|    4|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|    2|    2|\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|    4|     |\n",
      "-------------------------\n",
      "|    4|    2|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    8|     |     |\n",
      "-------------------------\n",
      "|    4|    4|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 576\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|   16|     |    2|     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |     |\n",
      "-------------------------\n",
      "|   16|    2|     |    2|\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|     |    2|\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|    2|    2|\n",
      "-------------------------\n",
      "|   16|    4|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|     |   16|    4|    2|\n",
      "-------------------------\n",
      "|     |     |    8|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    4|    2|    2|\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    4|    4|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|     |     |\n",
      "-------------------------\n",
      "|    8|    4|    4|    4|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|     |    2|\n",
      "-------------------------\n",
      "|    8|    8|    4|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   16|    8|    2|     |\n",
      "-------------------------\n",
      "|   16|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 1296\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|     |    4|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    4|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|     |\n",
      "-------------------------\n",
      "|    4|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|    2|\n",
      "-------------------------\n",
      "|    8|    2|     |     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|    2|\n",
      "-------------------------\n",
      "|    2|     |    8|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|    2|\n",
      "-------------------------\n",
      "|    2|    8|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|    8|    4|    2|\n",
      "-------------------------\n",
      "|    2|    8|    4|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 784\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|     |     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 576\n",
      "-------------------------\n",
      "|  256|   64|   16|    8|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   16|    2|     |\n",
      "-------------------------\n",
      "|    4|    2|     |     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 2304\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    2|     |\n",
      "-------------------------\n",
      "|   32|   16|     |     |\n",
      "-------------------------\n",
      "|    4|    2|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    2|     |\n",
      "-------------------------\n",
      "|   32|   16|     |     |\n",
      "-------------------------\n",
      "|    4|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    2|     |\n",
      "-------------------------\n",
      "|   32|   16|     |     |\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    2|     |\n",
      "-------------------------\n",
      "|   32|   16|     |    2|\n",
      "-------------------------\n",
      "|    8|    4|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    2|     |\n",
      "-------------------------\n",
      "|   32|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    2|    2|\n",
      "-------------------------\n",
      "|   32|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|   32|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|   32|   16|    4|     |\n",
      "-------------------------\n",
      "|    8|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    4|    2|\n",
      "-------------------------\n",
      "|   32|   16|    4|    2|\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    2|     |\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    4|     |\n",
      "-------------------------\n",
      "|    8|    4|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    4|    2|\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    4|    2|\n",
      "-------------------------\n",
      "|    2|    8|    4|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|    8|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|    8|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|    8|    4|\n",
      "-------------------------\n",
      "|   32|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|    8|    4|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 576\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   16|    4|    2|\n",
      "-------------------------\n",
      "|    2|    8|    2|     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   16|    4|    2|\n",
      "-------------------------\n",
      "|    2|    2|    8|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   16|    4|    2|\n",
      "-------------------------\n",
      "|    4|    8|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   16|    4|    2|\n",
      "-------------------------\n",
      "|    4|    8|    4|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 144\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   16|    8|    4|\n",
      "-------------------------\n",
      "|    4|    8|    2|     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|    4|    8|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 256\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   16|   16|    4|\n",
      "-------------------------\n",
      "|    2|    4|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 1296\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   32|   32|    4|     |\n",
      "-------------------------\n",
      "|    2|    4|    4|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 5184\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|    4|     |    2|\n",
      "-------------------------\n",
      "|    2|    8|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|    4|    2|    2|\n",
      "-------------------------\n",
      "|    2|    8|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|    4|    4|    4|\n",
      "-------------------------\n",
      "|    2|    8|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|    8|    4|     |\n",
      "-------------------------\n",
      "|    2|    8|    2|    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|    8|    4|    2|\n",
      "-------------------------\n",
      "|    2|    8|    4|     |\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 576\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    2|\n",
      "-------------------------\n",
      "|    2|    2|     |     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    2|\n",
      "-------------------------\n",
      "|    4|     |     |    2|\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: left\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    2|\n",
      "-------------------------\n",
      "|    4|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    2|\n",
      "-------------------------\n",
      "|    4|    4|    2|     |\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 64\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    2|\n",
      "-------------------------\n",
      "|    8|    2|     |    2|\n",
      "-------------------------\n",
      "Action: left\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    2|\n",
      "-------------------------\n",
      "|    8|    4|    2|     |\n",
      "-------------------------\n",
      "Action: right\n",
      "Reward: 0\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    2|\n",
      "-------------------------\n",
      "|    2|    8|    4|    2|\n",
      "-------------------------\n",
      "Action: up\n",
      "Reward: 16\n",
      "-------------------------\n",
      "|  256|   64|   32|   16|\n",
      "-------------------------\n",
      "|    2|   32|   16|    8|\n",
      "-------------------------\n",
      "|   64|   16|    8|    4|\n",
      "-------------------------\n",
      "|    2|    8|    4|    2|\n",
      "-------------------------\n",
      "Score: 2792\n",
      "Max Value: 256\n",
      "Game over.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from keras.models import load_model\n",
    "from gamelogic.game import Game, ACTION_NAMES\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "\n",
    "def play_single_game():\n",
    "    \"\"\"Play a single game using the latest model snapshot\"\"\"\n",
    "    game = Game()\n",
    "    state_size = 16\n",
    "    debug = True\n",
    "\n",
    "\n",
    "\n",
    "    model = load_model(path + \"/data/checkpoint\")\n",
    "  \n",
    "    game.new_game()\n",
    "    state = game.state()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    while not game.game_over():\n",
    "        # get action from highest q-value\n",
    "        act_values = model.predict(state)\n",
    "        if len(game.available_actions())< 4:\n",
    "          temp = game.available_actions()\n",
    "          for i in range(0, 4):\n",
    "            if i not in temp:\n",
    "              act_values[0][i] = -100\n",
    "        #returns action with highest q-value\n",
    "        action = np.argmax(act_values[0])\n",
    "        \n",
    "        reward = (game.do_action(action))**2\n",
    "        next_state = game.state()\n",
    "        actions_available = game.available_actions()\n",
    "        if len(actions_available) == 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        state = next_state\n",
    "        print(\"Action:\", ACTION_NAMES[action])\n",
    "        print(\"Reward:\", reward)\n",
    "        game.print_state()\n",
    "\n",
    "        if done:\n",
    "            states = game.state()\n",
    "            states = np.reshape(state, [1, state_size])\n",
    "            max_value = np.amax(states[0])\n",
    "            print(\"Score:\", game.score())\n",
    "            print(\"Max Value: \" + str(2**max_value))\n",
    "            print(\"Game over.\")\n",
    "            break\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  \"\"\"Main function.\"\"\"\n",
    "  play_single_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "When we chose the game, we knew that it would be a hard one to play. Even for a human, there is no clear and obvious strategy in this game. <br>\n",
    "As expected the results were not extremely high.\n",
    "Training speed was slower then expected (3.5min/1000-game-episode), which was also caused by the rather slow hardware we were using. We also found that using a gpu did not increase the training speed, probably because of the low specs of the graphics card we used (gtx760 2GB).\n",
    "This made it difficult to play through the high amount of possible hyperparameter configurations.\n",
    "Still our agent is consistently beating a random player and is reaching a 1028 tile in some games, which is already rather hard to do for an unexperienced player.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
